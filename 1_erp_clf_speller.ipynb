{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad9c091",
   "metadata": {},
   "source": [
    "# Machine Learning Classifier Evaluation\n",
    "\n",
    "Fit a range of ML classifiers to each subject in the  study, and create a table of metrics, including mean accuracy from 10-fold stratified cross-validation, and generalization accuracy of the model to a test set (20% of original data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea0a9d-cb6b-4e7d-8f7c-15e93f0baf17",
   "metadata": {},
   "source": [
    "### Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af434608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "import os.path as op\n",
    "# MNE\n",
    "import mne\n",
    "from mne import io, EvokedArray\n",
    "from mne.decoding import Vectorizer, get_coef\n",
    "from mne.decoding import LinearModel\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "mne.set_log_level(verbose='Warning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e10fd-3f1f-455d-af67-862d8d0339d0",
   "metadata": {},
   "source": [
    "### Yaml + Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36183994-ff8f-436d-8daf-5aea71305c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YAML\n",
    "with open('config.yml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['study_name']\n",
    "task = config['task']\n",
    "data_type = config['data_type']\n",
    "eog = config['eog']\n",
    "montage_fname = config['montage_fname']\n",
    "n_jobs = -1\n",
    "\n",
    "epoch_p =  {k: v for d in config['preprocessing_settings']['epoch'] for k, v in d.items()}\n",
    "\n",
    "cl_p = {k: v for d in config['classification'] for k, v in d.items()}\n",
    "\n",
    "## Pathing\n",
    "results_path = op.join('results', 'classification_test_' + str(cl_p['test_size'])[-1] + '0_pct')\n",
    "if Path(results_path).exists() == False:\n",
    "    Path(results_path).mkdir(parents=True)\n",
    "    \n",
    "report_path = op.join(results_path, 'reports')\n",
    "if Path(report_path).exists() == False:\n",
    "    Path(report_path).mkdir(parents=True)\n",
    "\n",
    "fig_path = op.join(results_path, 'figures')\n",
    "if Path(fig_path).exists() == False:\n",
    "    Path(fig_path).mkdir(parents=True) \n",
    "\n",
    "tab_path = op.join(results_path, 'tables')\n",
    "if Path(tab_path).exists() == False:\n",
    "    Path(tab_path).mkdir(parents=True) \n",
    "    \n",
    "epochs_suffix = '-epo.fif'\n",
    "\n",
    "# Output files\n",
    "out_file = op.join(tab_path, 'classification_overall_results.csv')\n",
    "summary_file =  op.join(tab_path, 'classification_accuracy_summary.csv')\n",
    "plot_stem = op.join(fig_path, 'plot_')\n",
    "fig_format = 'pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac278d2b-fe69-4e2e-bb00-1e40555e98f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define conditions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af902a6-594d-44e6-aefe-ac5738f8fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Angry/Grey/target', 'Angry/Grey/nontarget',\n",
    "              'Angry/Red/target', 'Angry/Red/nontarget',\n",
    "              'Neutral/Grey/target', 'Neutral/Grey/nontarget',\n",
    "              'Neutral/Red/target', 'Neutral/Red/nontarget',\n",
    "              'target', 'nontarget'\n",
    "             ]\n",
    "\n",
    "coi = ['target', 'nontarget']\n",
    "\n",
    "contrasts = {'Angry/Grey':['Angry/Grey/target', 'Angry/Grey/nontarget'],\n",
    "             'Angry/Red':['Angry/Red/target', 'Angry/Red/nontarget'],\n",
    "             'Neutral/Grey':['Neutral/Grey/target', 'Neutral/Grey/nontarget'],\n",
    "             'Neutral/Red':['Neutral/Red/target', 'Neutral/Red/nontarget'],\n",
    "             'Target-Nontarget':['target', 'nontarget']\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579d344",
   "metadata": {},
   "source": [
    "## Instantiating classifiers, parameter grids, and scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "vectorizer = Vectorizer()\n",
    "\n",
    "logreg = LinearModel(LogisticRegression(solver='lbfgs', max_iter=1000, n_jobs=n_jobs, verbose=False, random_state=rng))\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "svc = LinearSVC(C=8, max_iter=10000, verbose=False, random_state=rng) \n",
    "\n",
    "classifiers = {'LR':logreg, 'LDA':lda, 'SVM':svc}\n",
    "\n",
    "# For cross-validation\n",
    "k = 10\n",
    "cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769d6f3-5495-4ce7-923e-ada0f5a70008",
   "metadata": {},
   "source": [
    "## Define Subjects & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414ce21-b822-4487-9e2c-ca00eb02fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Running Individual participants\n",
    "subjects = ['sub-004', 'sub-005']\n",
    "print(\"n subjects = \", len(subjects))\n",
    "\n",
    "## Reading in data\n",
    "epochs = {}\n",
    "print('Loading Subjects:', subjects)\n",
    "for subject in subjects:\n",
    "    raw_path = op.join('./', 'data')\n",
    "    raw_subj = glob(op.join(raw_path + '/' + '*-epo.fif'))\n",
    "    epochs[subject] = mne.read_epochs(raw_subj.pop(), proj=False, verbose=False, preload=True)\n",
    "    \n",
    "    # Correcting for presentation delay\n",
    "    epochs[subject]._raw_times = epochs[subject]._raw_times - epoch_p['tshift']\n",
    "    epochs[subject]._times_readonly = epochs[subject]._times_readonly - epoch_p['tshift']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc55869-8eba-4e08-a59c-23f12865844c",
   "metadata": {},
   "source": [
    "## Classification loop\n",
    "For each subject and condition, fit each classifier and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4cf84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acc_tab = pd.DataFrame()\n",
    "acc_tab_list = []\n",
    "\n",
    "for subject in subjects:\n",
    "    print('\\n-------\\n' + subject)\n",
    "    \n",
    "    for contr, conds in contrasts.items():\n",
    "        print('-------\\n' + contr)\n",
    "        subj_epochs = epochs[subject][conds]\n",
    "\n",
    "        # create a list of labels from event codes mapped to event_id\n",
    "        event_id_rev = dict(zip(subj_epochs.event_id.values(), subj_epochs.event_id.keys()))\n",
    "        labels_all = [event_id_rev[e] for e in subj_epochs.events[:, 2]]\n",
    "        labels_all = pd.DataFrame(labels_all)[0].str.split('/', expand=True).rename(columns={0:'Emotion', 1:'Colour', 2:'Status', 3:'Location'})\n",
    "        label_map = {'target':1, 'nontarget':0}\n",
    "        labels_all['labels'] = labels_all['Status'].map(label_map)\n",
    "        labels = labels_all['labels']\n",
    "\n",
    "        # Extract data from subj_epochs and vectorize \n",
    "        X = subj_epochs.get_data()    \n",
    "\n",
    "        # Create train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, labels,\n",
    "                                                            stratify=labels,\n",
    "                                                            test_size=cl_p['test_size'], \n",
    "                                                            random_state=42)\n",
    "\n",
    "        for c_name, c in classifiers.items():\n",
    "            print('-------\\nRunning classifier: ' + c_name)\n",
    "            clf = Pipeline([('Vectorizer', vectorizer),\n",
    "                            ('Scaler', scaler),\n",
    "                            (c_name, c)\n",
    "                           ])\n",
    "\n",
    "    #         kf_scores = cross_val_score(clf, X_train, y_train, cv=cv)\n",
    "            # Fit model then get prediction accuracy on test set\n",
    "            print('Cross validate...')\n",
    "            cv_cv = cross_validate(clf, X_train, y_train, \n",
    "                                   scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], \n",
    "                                   cv=cv,\n",
    "                                   n_jobs=n_jobs)      \n",
    "            print('Training...')\n",
    "            train_fit = clf.fit(X_train, y_train)\n",
    "            print('Predicting...')\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            print('Scoring...')\n",
    "            # test_score = clf.score(X_test, y_test)\n",
    "\n",
    "            acc_tab_list.append(pd.DataFrame({'participant_id':subject,\n",
    "                                              'Condition':contr,\n",
    "                                              'Classifier':c_name,\n",
    "                                              'CV_accuracy':cv_cv['test_accuracy'].mean().round(3) * 100,\n",
    "                                              'Test_accuracy':accuracy_score(y_test, y_pred).round(3) * 100,\n",
    "                                              \n",
    "                                              'CV_precision':cv_cv['test_precision'].mean().round(3) * 100,\n",
    "                                              'Test_precision':precision_score(y_test, y_pred).round(3) * 100,\n",
    "                                              \n",
    "                                              'CV_recall':cv_cv['test_recall'].mean().round(3) * 100,\n",
    "                                              'Test_recall':recall_score(y_test, y_pred).round(3) * 100,\n",
    "                                              \n",
    "                                              'CV_f1':cv_cv['test_f1'].mean().round(3) * 100,\n",
    "                                              'Test_f1':f1_score(y_test, y_pred).round(3) * 100,\n",
    "                                              \n",
    "                                              'CV_ROC_AUC':cv_cv['test_roc_auc'].mean().round(3) * 100,\n",
    "                                              'Test_ROC_AUC':roc_auc_score(y_test, y_pred).round(3) * 100,\n",
    "                                              \n",
    "                                              'Fit Time':cv_cv['fit_time'].mean().round(3)\n",
    "                                             }, index=[0]\n",
    "                                            )\n",
    "                               )\n",
    "# compile accuracy results                            \n",
    "acc_tab = pd.concat(acc_tab_list)\n",
    "\n",
    "# save compiled results as CSV file in `results` folder\n",
    "acc_tab.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735008b",
   "metadata": {},
   "source": [
    "## Full results grouped by participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f845f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_tab.groupby(['participant_id', 'Condition', 'Classifier']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c25b930-19f5-45d5-bda0-b978d8aa509b",
   "metadata": {},
   "source": [
    "## Average across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151f896-3879-45cb-b8ac-ac5bfd22d1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_tab.groupby(['Condition', 'Classifier']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b960ec-04fc-4b6f-bed9-e81a87410bae",
   "metadata": {},
   "source": [
    "### Descriptive statistics on above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ca22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "descr_tab = acc_tab.groupby(['Condition', 'Classifier']).describe()\n",
    "descr_tab.to_csv(summary_file)\n",
    "descr_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e83bef",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df70566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "ax = sns.catplot(kind='strip', \n",
    "            data=acc_tab,\n",
    "            y='Test_accuracy', x='Condition', hue='Classifier', col='participant_id',\n",
    "            aspect=.5\n",
    "            )\n",
    "ax.set_xticklabels(rotation = 30)\n",
    "ax.savefig(plot_stem + 'accuracy_swarmplot_by_subj' + '.' + fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "ax = sns.catplot(kind='swarm', \n",
    "            data=acc_tab,\n",
    "            y='Test_precision', x='Condition', hue='Classifier', col='participant_id',\n",
    "            aspect=.5\n",
    "            )\n",
    "ax.set_xticklabels(rotation = 30)\n",
    "ax.savefig(plot_stem + 'precision_swarmplot_by_subj' + '.' + fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e4e25-3a98-4901-bf96-7099c9b08546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "ax = sns.catplot(kind='swarm', \n",
    "            data=acc_tab,\n",
    "            y='Test_recall', x='Condition', hue='Classifier', col='participant_id',\n",
    "            aspect=.5\n",
    "            )\n",
    "ax.set_xticklabels(rotation = 30)\n",
    "ax.savefig(plot_stem + 'precision_swarmplot_by_subj' + '.' + fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efbd03-603a-4eb6-b454-fbd5e02696de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 score\n",
    "ax = sns.catplot(kind='swarm', \n",
    "            data=acc_tab,\n",
    "            y='Test_f1', x='Condition', hue='Classifier', col='participant_id',\n",
    "            aspect=.5\n",
    "            )\n",
    "ax.set_xticklabels(rotation = 30)\n",
    "ax.savefig(plot_stem + 'precision_swarmplot_by_subj' + '.' + fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db66a4f-339b-4a5b-beb1-fd01d68373f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "760055932674735d287fd612619c18ffc3840c7c49c197eeb438d57975a1e213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
